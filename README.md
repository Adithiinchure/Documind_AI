ğŸ§  DocuMind AI â€” RAG-based Document & URL Chat System (FastAPI + Streamlit + Groq + ChromaDB)

DocuMind AI is an intelligent Retrieval-Augmented Generation (RAG) system that allows users to upload PDFs, process URLs, and ask questions based on the extracted content.

The system uses:

âœ… FastAPI as backend
âœ… Streamlit as frontend UI
âœ… ChromaDB for vector storage
âœ… HuggingFace Embeddings for encoding
âœ… Groq LLM (Qwen3-32B) for generating fast, accurate answers
âœ… MMR (Corrective) & Adaptive ranking for better retrieval
âœ… Unstructured URL loader to extract text from websites

ğŸš€ Features
ğŸ“„ Upload and Process PDFs

Upload multiple PDFs at once.
PDF content is extracted, chunked, embedded, and stored in ChromaDB.

ğŸŒ Process URLs

Fetch webpage content directly from URLs and store them for RAG querying.

ğŸ§  Ask Questions

Query your knowledge base using two smart retrieval approaches:

Mode	Behavior
Adaptive Ranking	Retrieves best matches using similarity search
Corrective Ranking (MMR)	Reduces redundancy, improves diversity of retrieved documents
ğŸ’¬ Beautiful Streamlit UI

Drag & drop PDFs

Enter multiple URLs

Chatbox-style Q&A

Chat history

Smart backend connection check

ğŸ—ï¸ Tech Stack

Backend (FastAPI)

FastAPI

PyPDF2

LangChain

Groq API

ChromaDB

HuggingFace Embeddings

RecursiveCharacterTextSplitter

Frontend (Streamlit)

Streamlit UI

REST API communication

Chat history

File uploader

URL processor

ğŸ“‚ Project Structure
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI backend
â”‚   â”œâ”€â”€ chroma_db/               # Vector store
â”‚   â”œâ”€â”€ .env                     # API keys
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                   # Streamlit interface
â”‚
â”œâ”€â”€ README.md

ğŸ”‘ Environment Setup

Create a .env file in your /backend folder:

GROQ_API_KEY=your_groq_api_key
HF_INFERENCE_API_KEY=your_huggingface_api_key

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Start FastAPI Backend
cd backend
uvicorn main:app --reload


Backend URL â†’
http://127.0.0.1:8000

3ï¸âƒ£ Start Streamlit Frontend
cd frontend
streamlit run app.py


Frontend URL â†’
http://localhost:8501

ğŸ§  RAG Workflow
PDF/URL â†’ Extract Text â†’ Chunk â†’
Embed using MiniLM â†’ Store in ChromaDB â†’
Retrieve (Adaptive/MMR) â†’ Groq LLM â†’ Answer

ğŸ§ª Ranking Modes
1. Adaptive (Similarity Search)

Best for normal Q&A

Retrieves top-k chunks based on cosine similarity

2. Corrective (MMR Ranking)

Balances relevance + diversity

Avoids retrieving repeated or redundant chunks.

